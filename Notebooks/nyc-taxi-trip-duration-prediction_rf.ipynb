{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "rf_model.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPoki2ReFske"
      },
      "source": [
        "# NYC Taxi Trip Duration Prediction - Random Forest\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvrRxLPU9gsX"
      },
      "source": [
        "<a id=path></a>\n",
        "## Set Local Path\n",
        "We need to set the local path to read and write to the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1QqPc5CD5Sw",
        "outputId": "229bfaf3-aebe-4e9b-a4e9-ca6070dcd794"
      },
      "source": [
        "if 'google.colab' in str(get_ipython()):\r\n",
        "  print('Running on CoLab - Remove sample data')\r\n",
        "  !rm -r sample_data\r\n",
        "else:\r\n",
        "  print('Not running on CoLab - Continue')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on CoLab - Remove sample data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRo5__bUEXtP"
      },
      "source": [
        "# Import dataset from Amazon S3 storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAjlO-7DA6Fn",
        "outputId": "132ec6f6-bfde-4a61-d19b-9a3cc3b9a9a1"
      },
      "source": [
        "!wget https://seminar-ml-2020.s3.amazonaws.com/NYC_DS_After.zip -P ./datasets\r\n",
        "!unzip ./datasets/NYC_DS_After.zip -d ./datasets\r\n",
        "!rm ./datasets/NYC_DS_After.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-13 18:52:11--  https://seminar-ml-2020.s3.amazonaws.com/NYC_DS_After.zip\n",
            "Resolving seminar-ml-2020.s3.amazonaws.com (seminar-ml-2020.s3.amazonaws.com)... 52.217.111.28\n",
            "Connecting to seminar-ml-2020.s3.amazonaws.com (seminar-ml-2020.s3.amazonaws.com)|52.217.111.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 177761819 (170M) [application/zip]\n",
            "Saving to: ‘./datasets/NYC_DS_After.zip’\n",
            "\n",
            "NYC_DS_After.zip    100%[===================>] 169.53M  74.4MB/s    in 2.3s    \n",
            "\n",
            "2021-01-13 18:52:13 (74.4 MB/s) - ‘./datasets/NYC_DS_After.zip’ saved [177761819/177761819]\n",
            "\n",
            "Archive:  ./datasets/NYC_DS_After.zip\n",
            "  inflating: ./datasets/train_ds.csv  \n",
            "  inflating: ./datasets/test_ds.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0PNk3WGFski"
      },
      "source": [
        "<a id=library></a>\n",
        "# Import libraries\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO72co3IFskj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tqdm import tqdm\n",
        "from time import perf_counter\n",
        "\n",
        "# Import to Show image in Jupyter Notebook\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjLUYeGdFskj"
      },
      "source": [
        "<a id=data></a>\n",
        "# Import Dataset\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMyxY82KFskj",
        "outputId": "4f4f3aa9-2bc2-4363-f587-1d6b8e823d97"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anaconda3  datasets  rf_model.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKBm3nMSFskk"
      },
      "source": [
        "train_df=pd.read_csv(\"./datasets/train_ds.csv\")\n",
        "test_df=pd.read_csv(\"./datasets/test_ds.csv\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBscB076Fskk"
      },
      "source": [
        "DO_NOT_USE_FOR_TRAINING = ['id', 'pickup_datetime', 'dropoff_datetime','pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
        "       'dropoff_latitude', 'date',\n",
        "       'month', 'weekday', 'hour', 'minute', 'second', 'passenger_count',\n",
        "       'distance', 'best_travel_time', 'left',\n",
        "       'right', 'merge', 'on ramp', 'off ramp', 'fork', 'end of road',\n",
        "       'continue', 'roundabout', 'rotary', 'roundabout turn', \n",
        "       'average temperature','departure', 'HDD', 'CDD', 'snow fall', 'num_rides_by_pickup_group']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j2SZe62Fskl"
      },
      "source": [
        "train_df = train_df.drop([col for col in DO_NOT_USE_FOR_TRAINING if col in train_df], axis=1)\n",
        "new_test = test_df.drop([col for col in DO_NOT_USE_FOR_TRAINING if col in test_df], axis=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqTa1M9zkA3d",
        "outputId": "16ecea41-549f-4ece-cdad-818c5d1336b5"
      },
      "source": [
        "new_test.isnull().sum()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "store_and_fwd_flag            0\n",
              "is_weekend                    0\n",
              "is_holiday                    0\n",
              "is_near_holiday               0\n",
              "is_businessday                0\n",
              "minute_of_day                 0\n",
              "haversine_distance            0\n",
              "manhattan_distance            0\n",
              "pickup_pca                    0\n",
              "dropoff_pca                   0\n",
              "maximum temerature            0\n",
              "minimum temperature           0\n",
              "precipitation                 0\n",
              "snow depth                    0\n",
              "kmeans_pickup                 0\n",
              "kmeans_dropoff                0\n",
              "num_rides_by_dropoff_group    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8ojpXDvFskm"
      },
      "source": [
        "sample_train = train_df.sample(frac=0.4,random_state=1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee4oEiQpFskn"
      },
      "source": [
        "y = np.log(sample_train['trip_duration'].values)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKou4LpaFsko"
      },
      "source": [
        "# drop target\n",
        "sample_train = sample_train.drop(columns='trip_duration')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaaVvyK6Fsko"
      },
      "source": [
        "<a id=splitdata></a>\n",
        "## Split data to train and validation\n",
        "***\n",
        "For comparing the results for raw and optimized data, we'll split and use both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgnPWcGPFskp"
      },
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(sample_train, y, test_size=0.2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHN4wBUCFskp"
      },
      "source": [
        "<a id=rf></a>\n",
        "# Random Forest Regressor\n",
        "***\n",
        "A Random Forest is an ensemble technique using a technique called Bootstrap, commonly known as bagging - the basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.\n",
        "Bagging generates new training sets, each of size n, by sampling from the data randomly with replacement.\n",
        "The remaining samples are called Out-of-Bag dataset and are used for validation.\n",
        "\n",
        "Decision Trees tend to overfit, and to avoid overfitting we need to tune the hyper parameters:\n",
        "\n",
        "max_features - The maximum number of features Random Forest is allowed to try in individual tree, we need to find the number of sub-set features in order to create more versatile trees and reduce variance.\n",
        "\n",
        "n_estimators - The number of trees in the forest\n",
        "\n",
        "min_sample_leaf - The minimum number of samples in leaf, helps avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBoMAu1zFskp"
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [80, 100, 200, 500]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt', 'log2', None] # take all the features, take square root of the total number of features, take 20% of variables in individual run\n",
        "# Maximum depth of tree\n",
        "max_depth = [4, 6, 10, 14]\n",
        "#Minimu samples in leaf for split\n",
        "min_samples_split = [0.1, 0.01, 0.001]\n",
        "# Fracture of data for bootstrap \n",
        "max_samples = [0.6, 0.7, 0.8]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFFtPkEuFskq"
      },
      "source": [
        "params = {'n_estimators': 100,\n",
        "               'max_features': 'sqrt',\n",
        "               'max_depth': 4,\n",
        "               'min_samples_split': 0.01,\n",
        "               'max_samples': 0.6}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl1DJypGFskq"
      },
      "source": [
        "#from sklearn.model_selection import RandomizedSearchCV\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf_model = RandomForestRegressor(**params, n_jobs=-1)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSNHAZ6qFskq",
        "outputId": "f26a52dc-06cb-4080-aa93-b65a73a95d5f"
      },
      "source": [
        "start = perf_counter()\n",
        "for iter in tqdm(np.arange(100)):\n",
        "        rf_model.fit(sample_train, y)\n",
        "end = perf_counter()\n",
        "rf_train_time = end-start #in seconds"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/100 [00:28<46:17, 28.06s/it]\u001b[A\n",
            "  2%|▏         | 2/100 [00:56<46:01, 28.18s/it]\u001b[A\n",
            "  3%|▎         | 3/100 [01:23<45:06, 27.90s/it]\u001b[A\n",
            "  4%|▍         | 4/100 [01:51<44:27, 27.79s/it]\u001b[A\n",
            "  5%|▌         | 5/100 [02:18<43:36, 27.54s/it]\u001b[A\n",
            "  6%|▌         | 6/100 [02:45<43:06, 27.51s/it]\u001b[A\n",
            "  7%|▋         | 7/100 [03:13<42:34, 27.46s/it]\u001b[A\n",
            "  8%|▊         | 8/100 [03:40<42:11, 27.52s/it]\u001b[A\n",
            "  9%|▉         | 9/100 [04:10<42:50, 28.25s/it]\u001b[A\n",
            " 10%|█         | 10/100 [04:38<42:11, 28.13s/it]\u001b[A\n",
            " 11%|█         | 11/100 [05:05<41:22, 27.89s/it]\u001b[A\n",
            " 12%|█▏        | 12/100 [05:34<41:04, 28.00s/it]\u001b[A\n",
            " 13%|█▎        | 13/100 [06:01<40:19, 27.81s/it]\u001b[A\n",
            " 14%|█▍        | 14/100 [06:29<39:55, 27.85s/it]\u001b[A\n",
            " 15%|█▌        | 15/100 [06:57<39:27, 27.85s/it]\u001b[A\n",
            " 16%|█▌        | 16/100 [07:24<38:52, 27.76s/it]\u001b[A\n",
            " 17%|█▋        | 17/100 [07:52<38:26, 27.79s/it]\u001b[A\n",
            " 18%|█▊        | 18/100 [08:20<38:00, 27.81s/it]\u001b[A\n",
            " 19%|█▉        | 19/100 [08:47<37:11, 27.55s/it]\u001b[A\n",
            " 20%|██        | 20/100 [09:14<36:20, 27.25s/it]\u001b[A\n",
            " 21%|██        | 21/100 [09:40<35:40, 27.10s/it]\u001b[A\n",
            " 22%|██▏       | 22/100 [10:07<35:01, 26.94s/it]\u001b[A\n",
            " 23%|██▎       | 23/100 [10:34<34:34, 26.94s/it]\u001b[A\n",
            " 24%|██▍       | 24/100 [11:00<34:00, 26.85s/it]\u001b[A\n",
            " 25%|██▌       | 25/100 [11:27<33:20, 26.67s/it]\u001b[A\n",
            " 26%|██▌       | 26/100 [11:53<32:35, 26.42s/it]\u001b[A\n",
            " 27%|██▋       | 27/100 [12:19<32:02, 26.34s/it]\u001b[A\n",
            " 28%|██▊       | 28/100 [12:45<31:45, 26.46s/it]\u001b[A\n",
            " 29%|██▉       | 29/100 [13:13<31:35, 26.70s/it]\u001b[A\n",
            " 30%|███       | 30/100 [13:39<31:03, 26.63s/it]\u001b[A\n",
            " 31%|███       | 31/100 [14:05<30:31, 26.54s/it]\u001b[A\n",
            " 32%|███▏      | 32/100 [14:35<31:01, 27.38s/it]\u001b[A\n",
            " 33%|███▎      | 33/100 [15:02<30:21, 27.19s/it]\u001b[A\n",
            " 34%|███▍      | 34/100 [15:28<29:45, 27.05s/it]\u001b[A\n",
            " 35%|███▌      | 35/100 [15:55<29:14, 26.99s/it]\u001b[A\n",
            " 36%|███▌      | 36/100 [16:22<28:43, 26.92s/it]\u001b[A\n",
            " 37%|███▋      | 37/100 [16:48<28:09, 26.81s/it]\u001b[A\n",
            " 38%|███▊      | 38/100 [17:15<27:33, 26.67s/it]\u001b[A\n",
            " 39%|███▉      | 39/100 [17:42<27:12, 26.76s/it]\u001b[A\n",
            " 40%|████      | 40/100 [18:09<26:45, 26.76s/it]\u001b[A\n",
            " 41%|████      | 41/100 [18:36<26:24, 26.85s/it]\u001b[A\n",
            " 42%|████▏     | 42/100 [19:03<25:59, 26.88s/it]\u001b[A\n",
            " 43%|████▎     | 43/100 [19:29<25:33, 26.90s/it]\u001b[A\n",
            " 44%|████▍     | 44/100 [19:56<25:04, 26.86s/it]\u001b[A\n",
            " 45%|████▌     | 45/100 [20:24<24:53, 27.16s/it]\u001b[A\n",
            " 46%|████▌     | 46/100 [20:51<24:24, 27.13s/it]\u001b[A\n",
            " 47%|████▋     | 47/100 [21:18<23:58, 27.13s/it]\u001b[A\n",
            " 48%|████▊     | 48/100 [21:46<23:37, 27.26s/it]\u001b[A\n",
            " 49%|████▉     | 49/100 [22:13<23:06, 27.19s/it]\u001b[A\n",
            " 50%|█████     | 50/100 [22:40<22:43, 27.27s/it]\u001b[A\n",
            " 51%|█████     | 51/100 [23:09<22:32, 27.60s/it]\u001b[A\n",
            " 52%|█████▏    | 52/100 [23:38<22:30, 28.13s/it]\u001b[A\n",
            " 53%|█████▎    | 53/100 [24:05<21:48, 27.83s/it]\u001b[A\n",
            " 54%|█████▍    | 54/100 [24:35<21:49, 28.46s/it]\u001b[A\n",
            " 55%|█████▌    | 55/100 [25:04<21:20, 28.46s/it]\u001b[A\n",
            " 56%|█████▌    | 56/100 [25:30<20:30, 27.98s/it]\u001b[A\n",
            " 57%|█████▋    | 57/100 [25:57<19:47, 27.61s/it]\u001b[A\n",
            " 58%|█████▊    | 58/100 [26:24<19:09, 27.38s/it]\u001b[A\n",
            " 59%|█████▉    | 59/100 [26:51<18:36, 27.22s/it]\u001b[A\n",
            " 60%|██████    | 60/100 [27:18<18:06, 27.17s/it]\u001b[A\n",
            " 61%|██████    | 61/100 [27:46<17:49, 27.43s/it]\u001b[A\n",
            " 62%|██████▏   | 62/100 [28:12<17:10, 27.11s/it]\u001b[A\n",
            " 63%|██████▎   | 63/100 [28:40<16:44, 27.15s/it]\u001b[A\n",
            " 64%|██████▍   | 64/100 [29:07<16:16, 27.12s/it]\u001b[A\n",
            " 65%|██████▌   | 65/100 [29:34<15:50, 27.16s/it]\u001b[A\n",
            " 66%|██████▌   | 66/100 [30:01<15:26, 27.25s/it]\u001b[A\n",
            " 67%|██████▋   | 67/100 [30:28<14:50, 26.98s/it]\u001b[A\n",
            " 68%|██████▊   | 68/100 [30:55<14:25, 27.06s/it]\u001b[A\n",
            " 69%|██████▉   | 69/100 [31:22<13:57, 27.03s/it]\u001b[A\n",
            " 70%|███████   | 70/100 [31:48<13:22, 26.77s/it]\u001b[A\n",
            " 71%|███████   | 71/100 [32:14<12:51, 26.61s/it]\u001b[A\n",
            " 72%|███████▏  | 72/100 [32:40<12:18, 26.38s/it]\u001b[A\n",
            " 73%|███████▎  | 73/100 [33:07<12:00, 26.67s/it]\u001b[A\n",
            " 74%|███████▍  | 74/100 [33:35<11:39, 26.91s/it]\u001b[A\n",
            " 75%|███████▌  | 75/100 [34:02<11:15, 27.01s/it]\u001b[A\n",
            " 76%|███████▌  | 76/100 [34:30<10:51, 27.15s/it]\u001b[A\n",
            " 77%|███████▋  | 77/100 [34:59<10:39, 27.82s/it]\u001b[A\n",
            " 78%|███████▊  | 78/100 [35:26<10:09, 27.69s/it]\u001b[A\n",
            " 79%|███████▉  | 79/100 [35:55<09:48, 28.01s/it]\u001b[A\n",
            " 80%|████████  | 80/100 [36:22<09:15, 27.75s/it]\u001b[A\n",
            " 81%|████████  | 81/100 [36:51<08:49, 27.87s/it]\u001b[A\n",
            " 82%|████████▏ | 82/100 [37:18<08:22, 27.90s/it]\u001b[A\n",
            " 83%|████████▎ | 83/100 [37:46<07:50, 27.70s/it]\u001b[A\n",
            " 84%|████████▍ | 84/100 [38:13<07:21, 27.57s/it]\u001b[A\n",
            " 85%|████████▌ | 85/100 [38:40<06:50, 27.36s/it]\u001b[A\n",
            " 86%|████████▌ | 86/100 [39:07<06:21, 27.23s/it]\u001b[A\n",
            " 87%|████████▋ | 87/100 [39:34<05:52, 27.15s/it]\u001b[A\n",
            " 88%|████████▊ | 88/100 [40:01<05:24, 27.06s/it]\u001b[A\n",
            " 89%|████████▉ | 89/100 [40:28<04:57, 27.06s/it]\u001b[A\n",
            " 90%|█████████ | 90/100 [40:54<04:27, 26.79s/it]\u001b[A\n",
            " 91%|█████████ | 91/100 [41:21<04:00, 26.77s/it]\u001b[A\n",
            " 92%|█████████▏| 92/100 [41:46<03:31, 26.50s/it]\u001b[A\n",
            " 93%|█████████▎| 93/100 [42:12<03:04, 26.31s/it]\u001b[A\n",
            " 94%|█████████▍| 94/100 [42:39<02:37, 26.32s/it]\u001b[A\n",
            " 95%|█████████▌| 95/100 [43:09<02:17, 27.45s/it]\u001b[A\n",
            " 96%|█████████▌| 96/100 [43:36<01:50, 27.55s/it]\u001b[A\n",
            " 97%|█████████▋| 97/100 [44:04<01:22, 27.50s/it]\u001b[A\n",
            " 98%|█████████▊| 98/100 [44:31<00:54, 27.40s/it]\u001b[A\n",
            " 99%|█████████▉| 99/100 [45:00<00:27, 27.87s/it]\u001b[A\n",
            "100%|██████████| 100/100 [45:27<00:00, 27.28s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA83XP-Oin8w",
        "outputId": "297079a4-f1ac-410f-c7c9-936511fc0a93"
      },
      "source": [
        "rf_train_time"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2727.7934546550005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooNrgvnzFskr"
      },
      "source": [
        "y_pred = rf_model.predict(val_x)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va7VNwhWFskr",
        "outputId": "81dbbb7f-c666-4a84-fb83-2f3af8b6e75c"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "rf_rmsle = np.sqrt(metrics.mean_squared_log_error(val_y,y_pred))\n",
        "rf_rmsle = np.sqrt(metrics.mean_squared_error(val_y,y_pred))  # for comparison\n",
        "print('RMSLE score for the RF regressor is : {}'.format(rf_rmsle))\n",
        "print('RMSE score for the RF regressor is : {}'.format(rf_rmsle))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSLE score for the RF regressor is : 0.44660445701889384\n",
            "RMSE score for the RF regressor is : 0.44660445701889384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt8bM_DlFsks",
        "outputId": "c7c521ed-7b70-47ba-a0d6-506c94f987fa"
      },
      "source": [
        "pred_rf = rf_model.predict(new_test)\n",
        "pred_rf = np.exp(pred_rf)\n",
        "print('Test shape OK.') if new_test.shape[0] == pred_rf.shape[0] else print('Oops')\n",
        "pred_rf"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test shape OK.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 693.33507192,  731.07243879,  452.28863076, ..., 1250.85513947,\n",
              "       1437.55404708,  975.66705962])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KXe79QIFsks"
      },
      "source": [
        "test_df['trip_duration'] = pred_rf"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPQJAx9MFsks"
      },
      "source": [
        "submission_rf = test_df[['id', 'trip_duration']]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "-G9v9fKCFskt",
        "outputId": "0d92f0c9-5e18-4797-9e86-c8c1cec01d9c"
      },
      "source": [
        "submission_rf"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id3004672</td>\n",
              "      <td>693.335072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id3505355</td>\n",
              "      <td>731.072439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id1217141</td>\n",
              "      <td>452.288631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id2150126</td>\n",
              "      <td>1168.683146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id1598245</td>\n",
              "      <td>401.244631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625129</th>\n",
              "      <td>id3008929</td>\n",
              "      <td>319.812385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625130</th>\n",
              "      <td>id3700764</td>\n",
              "      <td>1070.388951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625131</th>\n",
              "      <td>id2568735</td>\n",
              "      <td>1250.855139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625132</th>\n",
              "      <td>id1384355</td>\n",
              "      <td>1437.554047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625133</th>\n",
              "      <td>id0621643</td>\n",
              "      <td>975.667060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625134 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  trip_duration\n",
              "0       id3004672     693.335072\n",
              "1       id3505355     731.072439\n",
              "2       id1217141     452.288631\n",
              "3       id2150126    1168.683146\n",
              "4       id1598245     401.244631\n",
              "...           ...            ...\n",
              "625129  id3008929     319.812385\n",
              "625130  id3700764    1070.388951\n",
              "625131  id2568735    1250.855139\n",
              "625132  id1384355    1437.554047\n",
              "625133  id0621643     975.667060\n",
              "\n",
              "[625134 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vHDaln1Fskt"
      },
      "source": [
        "submission_rf.to_csv('submission-rf.csv',index=False)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcdOGVWgFskt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}